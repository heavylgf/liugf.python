# from pyspark import SparkContext, SparkConf

# conf = SparkConf()
#     .setAppName("appName")
#     .setMaster("master")
# sc = SparkContext(conf=conf)

# data = [1, 2, 3, 4, 5]
# distData = sc.parallelize(data)
# distData.collect()


# distFile = sc.textFile("d:/data.txt")
# distFile.collect()


# rdd1 = sc.textFile("d:/data.txt,d:/app.log")
# rdd1.collect()


# rdd2 = sc.textFile("d:/data.gz")
# rdd2.collect()




